{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "original_sys_path = sys.path.copy()\n",
    "\n",
    "sys.path.insert(0, \"/Users/florian/Documents/github/study/IoT/IoT/main/\")\n",
    "import dataprep as dp \n",
    "import foo\n",
    "\n",
    "sys.path = original_sys_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILEPATH = \"/Users/florian/Documents/github/study/IoT/IoT/data/aggregated_data/agg_hourly.parquet\"\n",
    "window_size = 50\n",
    "train_test_split_ratio = 0.8\n",
    "batch_size = 64\n",
    "\n",
    "features = [\"tmp\", \"CO2\", \"hum\", \"VOC\"]\n",
    "target = \"tmp\"\n",
    "scaling = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dp.create_DataLoader(filepath= FILEPATH, window_size= window_size, train_ratio= train_test_split_ratio, batch_size= batch_size, features= features, target= target, scaling= scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-20 19:11:02,021] A new study created in memory with name: LSTM\n",
      "Epoch [1/10]:  79%|███████▉  | 350/443 [00:11<00:03, 30.29it/s, loss=1.54, lr=0.0001] \n",
      "[W 2024-06-20 19:11:13,632] Trial 0 failed with parameters: {'hidden_size': 50, 'num_layers': 2, 'activation': 'relu', 'dropout': 0} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/var/folders/fm/5lbdpfj928d6sqhy_19cp6ww0000gn/T/ipykernel_36452/1713140457.py\", line 37, in objective\n",
      "    loss.backward()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/_tensor.py\", line 522, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/autograd/__init__.py\", line 266, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "KeyboardInterrupt\n",
      "[W 2024-06-20 19:11:13,647] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 54\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     53\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m'\u001b[39m, study_name\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLSTM\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 54\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m best_params \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_params\n\u001b[1;32m     57\u001b[0m best_loss \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_value\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/optuna/study/_optimize.py:62\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 62\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/optuna/study/_optimize.py:159\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 159\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/optuna/study/_optimize.py:247\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    243\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    246\u001b[0m ):\n\u001b[0;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/optuna/study/_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[17], line 37\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     35\u001b[0m output \u001b[38;5;241m=\u001b[39m model(features)\n\u001b[1;32m     36\u001b[0m loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mMSELoss()(output, target)\n\u001b[0;32m---> 37\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     40\u001b[0m loop\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mNUM_EPOCHS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from copy import deepcopy\n",
    "import os\n",
    "\n",
    "BASE_PATH = os.getenv('BASE_PATH', \"/Users/florian/Documents/github/study/IoT/IoT/\")\n",
    "sys.path.insert(0, os.path.join(BASE_PATH, \"main\"))\n",
    "\n",
    "# Set parameters\n",
    "FILEPATH = os.path.join(BASE_PATH, \"data/aggregated_data/agg_hourly.parquet\")\n",
    "FILEPATH_STUDY = os.path.join(BASE_PATH, \"models/train/LSTM_trials.csv\")\n",
    "\n",
    "NUM_EPOCHS = 10\n",
    "LEARNING_RATE = 0.0001\n",
    "FILEPATH_BEST_MODEL = \"/Users/florian/Documents/github/study/IoT/IoT/models/best_LSTM.pth\"\n",
    "\n",
    "models_and_losses = {}\n",
    "\n",
    "def objective(trial):\n",
    "    hidden_size = trial.suggest_categorical('hidden_size', [50, 100, 150])\n",
    "    num_layers = trial.suggest_categorical('num_layers', [1, 2, 3])\n",
    "    activation = trial.suggest_categorical('activation', ['relu', 'sigmoid', 'tanh'])\n",
    "    if num_layers == 1:\n",
    "        dropout = 0\n",
    "    else:    \n",
    "        dropout = trial.suggest_categorical('dropout', [0, 0.5, 1])\n",
    "\n",
    "    model = foo.LSTM(input_size= data[\"train\"].x.shape[2], hidden_size= hidden_size, num_layers= num_layers, output_size= 1, dropout= dropout, activation= activation)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr= LEARNING_RATE)\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        loop = tqdm(enumerate(data[\"train\"].loader), total=len(data[\"train\"].loader), leave=True)\n",
    "        for batch_idx, (features, target) in loop:\n",
    "            optimizer.zero_grad(set_to_none= True)\n",
    "            output = model(features)\n",
    "            loss = torch.nn.MSELoss()(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loop.set_description(f\"Epoch [{epoch+1}/{NUM_EPOCHS}]\")\n",
    "            loop.set_postfix(loss=loss.item(), lr= LEARNING_RATE)\n",
    "\n",
    "        trial.report(loss.item(), epoch)\n",
    "\n",
    "        if trial.should_prune():\n",
    "            logging.info(\"Trial was pruned at epoch {}.\".format(epoch))\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    models_and_losses[trial.number] = {\"model\": deepcopy(model), \"loss\": loss.item()}\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "study = optuna.create_study(direction= 'minimize', study_name= 'LSTM')\n",
    "study.optimize(objective, n_trials= 100)\n",
    "\n",
    "best_params = study.best_params\n",
    "best_loss = study.best_value\n",
    "min_loss = min_loss = min(models_and_losses.items(), key=lambda x: x[1]['loss'])\n",
    "\n",
    "logging.info(f\"Beste Hyperparameter: {best_params}\")\n",
    "logging.info(f\"Niedrigster Verlust: {best_loss}\")\n",
    "logging.info(f\"Modell mit geringstem Loss: {min_loss}\")\n",
    "torch.save(min_loss[1]['model'].state_dict(), FILEPATH_BEST_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    hidden_size = trial.suggest_categorical('hidden_size', [50, 100, 150])\n",
    "    num_layers = trial.suggest_categorical('num_layers', [1, 2, 3, 4])\n",
    "    activation = trial.suggest_categorical('activation', ['relu', 'sigmoid', 'tanh'])\n",
    "    if num_layers == 1:\n",
    "        dropout = 0\n",
    "    else:    \n",
    "        dropout = trial.suggest_categorical('dropout', [0, 0.5, 1])\n",
    "\n",
    "    model = foo.LSTM(input_size= data[\"train\"].x.shape[2], hidden_size= hidden_size, num_layers= num_layers, output_size= 1, dropout= dropout, activation= activation)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr= LEARNING_RATE)\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        loop = tqdm(enumerate(data[\"train\"].loader), total=len(data[\"train\"].loader), leave=True)\n",
    "        for batch_idx, (features, target) in loop:\n",
    "            optimizer.zero_grad(set_to_none= True)\n",
    "            output = model(features)\n",
    "            loss = torch.nn.MSELoss()(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loop.set_description(f\"Epoch [{epoch+1}/{NUM_EPOCHS}]\")\n",
    "            loop.set_postfix(loss=loss.item(), lr= LEARNING_RATE)\n",
    "            loop.update()\n",
    "\n",
    "        trial.report(loss.item(), epoch)\n",
    "\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "study = optuna.create_study(direction= 'minimize', study_name= 'LSTM')\n",
    "study.optimize(objective, n_trials= 100)\n",
    "\n",
    "best_params = study.best_params\n",
    "best_loss = study.best_value\n",
    "trials = study.trials_dataframe()\n",
    "trials.to_csv(FILEPATH_STUDY)\n",
    "\n",
    "logging.info(f\"Beste Hyperparameter: {best_params}\")\n",
    "logging.info(f\"Niedrigster Verlust: {best_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = foo.LSTM(input_size= data[\"train\"].x.shape[2], hidden_size= 100, num_layers= 3, output_size= 3, dropout= 0, activation= 'sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/443 [00:00<?, ?it/s]/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([64, 1])) that is different to the input size (torch.Size([64, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "Epoch [1/10]: 100%|█████████▉| 442/443 [00:28<00:00, 19.50it/s, loss=0.429, lr=0.0001]/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([32, 1])) that is different to the input size (torch.Size([32, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "Epoch [1/10]: 100%|██████████| 443/443 [00:28<00:00, 15.48it/s, loss=0.549, lr=0.0001]\n",
      "Epoch [2/10]: 100%|██████████| 443/443 [00:28<00:00, 15.37it/s, loss=0.506, lr=0.0001]\n",
      "Epoch [3/10]: 100%|██████████| 443/443 [00:28<00:00, 15.75it/s, loss=0.403, lr=0.0001]\n",
      "Epoch [4/10]: 100%|██████████| 443/443 [00:30<00:00, 14.64it/s, loss=0.62, lr=0.0001] \n",
      "Epoch [5/10]: 100%|██████████| 443/443 [00:28<00:00, 15.61it/s, loss=0.457, lr=0.0001]\n",
      "Epoch [6/10]: 100%|██████████| 443/443 [00:28<00:00, 15.68it/s, loss=0.567, lr=0.0001]\n",
      "Epoch [7/10]: 100%|██████████| 443/443 [00:28<00:00, 15.33it/s, loss=0.471, lr=0.0001]\n",
      "Epoch [8/10]: 100%|██████████| 443/443 [00:28<00:00, 15.51it/s, loss=0.598, lr=0.0001]\n",
      "Epoch [9/10]: 100%|██████████| 443/443 [00:28<00:00, 15.56it/s, loss=0.712, lr=0.0001]\n",
      "Epoch [10/10]: 100%|██████████| 443/443 [00:28<00:00, 15.43it/s, loss=0.188, lr=0.0001]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed. Final loss: 0.18818385899066925, final learning rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "num_epochs = 10\n",
    "learning_rate = 0.0001\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "train_loader = data[\"train\"].loader\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    loop = tqdm(enumerate(train_loader), total=len(train_loader), leave=True)\n",
    "    for i, (features, target) in loop:\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        output = model(features)\n",
    "        #target = target.unsqueeze(1)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update progress bar\n",
    "        loop.set_description(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "        loop.set_postfix(loss=loss.item(), lr= learning_rate)\n",
    "\n",
    "\n",
    "# Final output\n",
    "print(f\"Training completed. Final loss: {loss.item()}, final learning rate: {learning_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([64, 1])) that is different to the input size (torch.Size([64, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "model.eval()  \n",
    "test_loader = data[\"test\"].loader\n",
    "\n",
    "test_features, test_targets = next(iter(test_loader)) \n",
    "\n",
    "with torch.no_grad():  \n",
    "    predictions = model(test_features)  \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "feature_index = 0\n",
    "scaler = data[\"test\"].scaler\n",
    "\n",
    "\n",
    "feature_scaler = StandardScaler()\n",
    "feature_scaler.mean_ = scaler.mean_[feature_index]\n",
    "feature_scaler.scale_ = scaler.scale_[feature_index]\n",
    "\n",
    "inversed_predictions = feature_scaler.inverse_transform(predictions)\n",
    "inversed_targets = feature_scaler.inverse_transform(test_targets)\n",
    "\n",
    "\n",
    "train_loss = criterion(predictions, test_targets)\n",
    "print('Test Loss: {:.4f}'.format(train_loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines",
         "name": "test_targets",
         "type": "scatter",
         "y": [
          27.762499845787893,
          27.687499961372048,
          27.567500146306703,
          27.42750008974048,
          27.327500107691034,
          27.56499980975536,
          27.97000000257086,
          28.180000087420197,
          28.532000171288843,
          28.946841992683254,
          29.322499892547263,
          29.414166781042162,
          29.421818113168158,
          29.40200005596754,
          29.27749996189776,
          29.15499981028107,
          29.033333376504814,
          28.866666603594073,
          28.72000007218421,
          28.605000113251595,
          28.514999843467606,
          28.423333363457687,
          28.34249990506868,
          28.233333520109227,
          28.125000036020253,
          27.99750002827083,
          27.902499902354116,
          26.132499974987894,
          25.624666752556887,
          26.500476110595038,
          27.019999968858613,
          27.532499927922657,
          27.844374940871216,
          27.989090956510346,
          28.15400001856004,
          28.376000166612908,
          28.469999912818103,
          28.454999935934932,
          28.412499933351793,
          28.327499928185514,
          28.239999994952868,
          28.099999938386645,
          27.95749995375406,
          27.88499999740458,
          27.799999992238302,
          27.695000154056125,
          27.595000172006674,
          27.510000166840396,
          27.440000138557284,
          27.359999989523732,
          27.258571535505645,
          25.149999957321704,
          25.512857061303734,
          26.018571472153003,
          26.48071422007892,
          26.711785798284367,
          26.829999921267667,
          26.854000047674727,
          26.825000065134937,
          26.913333307723036,
          26.927999960864025,
          26.93800008161446,
          26.925000047184387,
          26.8833333539567
         ]
        },
        {
         "mode": "lines",
         "name": "Predictions",
         "type": "scatter",
         "y": [
          26.94864785529778,
          26.948693605615333,
          26.948684618945816,
          26.948646221357865,
          26.948687069855684,
          26.948683801975857,
          26.94864581287289,
          26.948684210460836,
          26.94868339349088,
          26.948646221357865,
          26.94868543591577,
          26.948684210460836,
          26.94864785529778,
          26.94868952076555,
          26.94868584440075,
          26.948652757117518,
          26.948702183799874,
          26.948690746220485,
          26.948655616512365,
          26.94870953652948,
          26.948693605615333,
          26.948659701362146,
          26.948718523199002,
          26.948697281980138,
          26.94866133530206,
          26.94872097410887,
          26.948698507435072,
          26.94866133530206,
          26.948720565623894,
          26.948698507435072,
          26.9486605183321,
          26.948716072289134,
          26.948698098950093,
          26.94865725045228,
          26.948703817739787,
          26.948696056525204,
          26.94864948923769,
          26.948673998336382,
          26.94868952076555,
          26.94863641771839,
          26.948627022563894,
          26.94867685773123,
          26.94862089528922,
          26.948581680731316,
          26.94865725045228,
          26.94860578134503,
          26.948549001933063,
          26.94863682620337,
          26.948599245585378,
          26.94853593041376,
          26.948627022563894,
          26.948602513465204,
          26.948546142538216,
          26.948631107413675,
          26.948611500134724,
          26.9485726940618,
          26.94864336196302,
          26.948622529229134,
          26.94860578134503,
          26.9486568419673,
          26.94863233286861,
          26.94863682620337,
          26.948668279546688,
          26.948638868628258,
          26.948659292877167,
          26.948675632276295,
          26.948642544993064,
          26.948672772881448,
          26.948679717126076,
          26.948644178932977,
          26.94867890015612,
          26.94868135106599,
          26.948644178932977,
          26.948679717126076,
          26.94868135106599,
          26.948642953478043,
          26.948677674701187,
          26.948680534096034,
          26.948641728023105,
          26.948673589851403,
          26.948679717126076,
          26.948640094083196,
          26.948669096516646,
          26.948678491671142,
          26.94863723468835,
          26.948662560756993,
          26.948676040761274,
          26.94863600923341,
          26.948662560756993,
          26.948675632276295,
          26.948643770447998,
          26.948683801975857,
          26.948682985005902,
          26.948647038327824,
          26.948693197130357,
          26.94868584440075,
          26.948646629842845,
          26.94869033773551,
          26.94868543591577,
          26.9486474468128,
          26.948689112280576,
          26.948686661370704,
          26.948643770447998,
          26.94867236439647,
          26.94868339349088,
          26.9486343752935,
          26.948638051658303,
          26.94867481530634,
          26.94862743104887,
          26.948611091649745,
          26.948667054091754,
          26.948615176499526,
          26.948575553456646,
          26.948651531662584,
          26.948606189830006,
          26.94855226981289,
          26.948638460143282,
          26.948599245585378,
          26.94853674738372,
          26.948628248018828,
          26.94859720316049,
          26.94853184556398,
          26.948624571654022,
          26.948600062555336,
          26.948537155868696,
          26.948628248018828,
          26.94860578134503,
          26.948549818903018,
          26.94863641771839,
          26.948613134074634,
          26.948566566787125,
          26.948646221357865,
          26.94862089528922,
          26.94858535709612,
          26.94865643348232,
          26.94862743104887,
          26.948604147405117,
          26.94866542015184,
          26.948633558323543,
          26.948622120744155,
          26.948672772881448,
          26.948638460143282,
          26.948638868628258,
          26.948678491671142,
          26.948642953478043,
          26.948653982572452,
          26.948682985005902,
          26.948647038327824,
          26.948668279546688,
          26.948687069855684,
          26.948650714692626,
          26.94868175955097,
          26.94869033773551,
          26.948653982572452,
          26.94869401410031,
          26.948693197130357,
          26.948654799542407,
          26.948702183799874,
          26.948693605615333,
          26.948654799542407,
          26.948708311074547,
          26.948693605615333,
          26.948655208027386,
          26.948712804409308,
          26.948693197130357,
          26.94865725045228,
          26.948717706229047,
          26.94869483107027,
          26.948658475907212,
          26.94872097410887,
          26.948695648040225,
          26.94865725045228,
          26.948720565623894,
          26.94869442258529,
          26.94865439105743,
          26.94871648077411,
          26.948691154705465,
          26.948647038327824,
          26.94870340925481,
          26.948684210460836,
          26.94862783953385,
          26.948658067422233,
          26.948667054091754,
          26.948559214057518,
          26.948501209190617,
          26.948591075885815,
          26.94840950431302,
          26.94823385577241,
          26.94840541946324,
          26.948257547901143,
          26.947983250238305,
          26.94822977092263
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "candlestick": [
           {
            "decreasing": {
             "line": {
              "color": "#000033"
             }
            },
            "increasing": {
             "line": {
              "color": "#000032"
             }
            },
            "type": "candlestick"
           }
          ],
          "contour": [
           {
            "colorscale": [
             [
              0,
              "#000011"
             ],
             [
              0.1111111111111111,
              "#000012"
             ],
             [
              0.2222222222222222,
              "#000013"
             ],
             [
              0.3333333333333333,
              "#000014"
             ],
             [
              0.4444444444444444,
              "#000015"
             ],
             [
              0.5555555555555556,
              "#000016"
             ],
             [
              0.6666666666666666,
              "#000017"
             ],
             [
              0.7777777777777778,
              "#000018"
             ],
             [
              0.8888888888888888,
              "#000019"
             ],
             [
              1,
              "#000020"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorscale": [
             [
              0,
              "#000011"
             ],
             [
              0.1111111111111111,
              "#000012"
             ],
             [
              0.2222222222222222,
              "#000013"
             ],
             [
              0.3333333333333333,
              "#000014"
             ],
             [
              0.4444444444444444,
              "#000015"
             ],
             [
              0.5555555555555556,
              "#000016"
             ],
             [
              0.6666666666666666,
              "#000017"
             ],
             [
              0.7777777777777778,
              "#000018"
             ],
             [
              0.8888888888888888,
              "#000019"
             ],
             [
              1,
              "#000020"
             ]
            ],
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorscale": [
             [
              0,
              "#000011"
             ],
             [
              0.1111111111111111,
              "#000012"
             ],
             [
              0.2222222222222222,
              "#000013"
             ],
             [
              0.3333333333333333,
              "#000014"
             ],
             [
              0.4444444444444444,
              "#000015"
             ],
             [
              0.5555555555555556,
              "#000016"
             ],
             [
              0.6666666666666666,
              "#000017"
             ],
             [
              0.7777777777777778,
              "#000018"
             ],
             [
              0.8888888888888888,
              "#000019"
             ],
             [
              1,
              "#000020"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram2d": [
           {
            "colorscale": [
             [
              0,
              "#000011"
             ],
             [
              0.1111111111111111,
              "#000012"
             ],
             [
              0.2222222222222222,
              "#000013"
             ],
             [
              0.3333333333333333,
              "#000014"
             ],
             [
              0.4444444444444444,
              "#000015"
             ],
             [
              0.5555555555555556,
              "#000016"
             ],
             [
              0.6666666666666666,
              "#000017"
             ],
             [
              0.7777777777777778,
              "#000018"
             ],
             [
              0.8888888888888888,
              "#000019"
             ],
             [
              1,
              "#000020"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "icicle": [
           {
            "textfont": {
             "color": "white"
            },
            "type": "icicle"
           }
          ],
          "sankey": [
           {
            "textfont": {
             "color": "#000036"
            },
            "type": "sankey"
           }
          ],
          "scatter": [
           {
            "marker": {
             "line": {
              "width": 0
             }
            },
            "type": "scatter"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#000038"
             },
             "font": {
              "color": "#000037"
             },
             "line": {
              "color": "#000039"
             }
            },
            "header": {
             "fill": {
              "color": "#000040"
             },
             "font": {
              "color": "#000036"
             },
             "line": {
              "color": "#000039"
             }
            },
            "type": "table"
           }
          ],
          "waterfall": [
           {
            "connector": {
             "line": {
              "color": "#000036",
              "width": 2
             }
            },
            "decreasing": {
             "marker": {
              "color": "#000033"
             }
            },
            "increasing": {
             "marker": {
              "color": "#000032"
             }
            },
            "totals": {
             "marker": {
              "color": "#000034"
             }
            },
            "type": "waterfall"
           }
          ]
         },
         "layout": {
          "coloraxis": {
           "colorscale": [
            [
             0,
             "#000011"
            ],
            [
             0.1111111111111111,
             "#000012"
            ],
            [
             0.2222222222222222,
             "#000013"
            ],
            [
             0.3333333333333333,
             "#000014"
            ],
            [
             0.4444444444444444,
             "#000015"
            ],
            [
             0.5555555555555556,
             "#000016"
            ],
            [
             0.6666666666666666,
             "#000017"
            ],
            [
             0.7777777777777778,
             "#000018"
            ],
            [
             0.8888888888888888,
             "#000019"
            ],
            [
             1,
             "#000020"
            ]
           ]
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#000021"
            ],
            [
             0.1,
             "#000022"
            ],
            [
             0.2,
             "#000023"
            ],
            [
             0.3,
             "#000024"
            ],
            [
             0.4,
             "#000025"
            ],
            [
             0.5,
             "#000026"
            ],
            [
             0.6,
             "#000027"
            ],
            [
             0.7,
             "#000028"
            ],
            [
             0.8,
             "#000029"
            ],
            [
             0.9,
             "#000030"
            ],
            [
             1,
             "#000031"
            ]
           ],
           "sequential": [
            [
             0,
             "#000011"
            ],
            [
             0.1111111111111111,
             "#000012"
            ],
            [
             0.2222222222222222,
             "#000013"
            ],
            [
             0.3333333333333333,
             "#000014"
            ],
            [
             0.4444444444444444,
             "#000015"
            ],
            [
             0.5555555555555556,
             "#000016"
            ],
            [
             0.6666666666666666,
             "#000017"
            ],
            [
             0.7777777777777778,
             "#000018"
            ],
            [
             0.8888888888888888,
             "#000019"
            ],
            [
             1,
             "#000020"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#000011"
            ],
            [
             0.1111111111111111,
             "#000012"
            ],
            [
             0.2222222222222222,
             "#000013"
            ],
            [
             0.3333333333333333,
             "#000014"
            ],
            [
             0.4444444444444444,
             "#000015"
            ],
            [
             0.5555555555555556,
             "#000016"
            ],
            [
             0.6666666666666666,
             "#000017"
            ],
            [
             0.7777777777777778,
             "#000018"
            ],
            [
             0.8888888888888888,
             "#000019"
            ],
            [
             1,
             "#000020"
            ]
           ]
          },
          "colorway": [
           "#000001",
           "#000002",
           "#000003",
           "#000004",
           "#000005",
           "#000006",
           "#000007",
           "#000008",
           "#000009",
           "#000010"
          ]
         }
        },
        "title": {
         "text": "test_targets vs predictions"
        },
        "xaxis": {
         "title": {
          "text": "Index"
         }
        },
        "yaxis": {
         "title": {
          "text": "Value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "def plt_pred(test_targets, predictions):\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(y=test_targets, mode='lines', name='test_targets'))\n",
    "    fig.add_trace(go.Scatter(y=predictions, mode='lines', name='Predictions'))\n",
    "    fig.update_layout(title='test_targets vs predictions', xaxis_title='Index', yaxis_title='Value')\n",
    "    fig.show()\n",
    "\n",
    "plt_pred(inversed_targets.reshape(-1).tolist(), inversed_predictions.reshape(-1).tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
